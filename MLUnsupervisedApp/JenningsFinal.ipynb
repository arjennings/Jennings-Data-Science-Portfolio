{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback\n",
    "- Make sure you can select feature variables, not only target variables\n",
    "- ROC curve code was apparently not working\n",
    "- Much more detailed code comments\n",
    "- Update portfolio readme to include info on all projects\n",
    "\n",
    "- Still include a requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /opt/anaconda3/lib/python3.12/site-packages (0.3.11)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset:  /Users/ardenjennings/.cache/kagglehub/datasets/subhamjain/loan-prediction-based-on-customer-behavior/versions/1\n"
     ]
    }
   ],
   "source": [
    "#installing kagglehub so I can import the data to my notebook\n",
    "%pip install kagglehub #this line is specific to Jupyter notebooks, use it in terminal if you are not in this environment\n",
    "import kagglehub #importing kagglehub to use its functions\n",
    "\n",
    "#downloading latests version of the dataset from kagglehub\n",
    "path = kagglehub.dataset_download(\"subhamjain/loan-prediction-based-on-customer-behavior\") #setting it equal to path to recall more easily later\n",
    "\n",
    "#displaying the path to the downloaded dataset\n",
    "print(\"Path to dataset: \", path) #printing the path to the dataset so that my output is easily readable\n",
    "\n",
    "import streamlit as st #importing streamlit to create a web app later\n",
    "import pandas as pd #importing pandas to work with the dataset\n",
    "import numpy as np #importing numpy to work with arrays and numerical data\n",
    "import matplotlib.pyplot as plt #importing matplotlib to create visualizations\n",
    "import seaborn as sns #importing seaborn to create more advanced visualizations\n",
    "import os #importing os to work with the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Married/Single</th>\n",
       "      <th>House_Ownership</th>\n",
       "      <th>Car_Ownership</th>\n",
       "      <th>Profession</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CURRENT_JOB_YRS</th>\n",
       "      <th>CURRENT_HOUSE_YRS</th>\n",
       "      <th>Risk_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1303834</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Mechanical_engineer</td>\n",
       "      <td>Rewa</td>\n",
       "      <td>Madhya_Pradesh</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Parbhani</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Technical_writer</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Civil_servant</td>\n",
       "      <td>Tiruchirappalli[10]</td>\n",
       "      <td>Tamil_Nadu</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Income  Age  Experience Married/Single House_Ownership Car_Ownership  \\\n",
       "0   1  1303834   23           3         single          rented            no   \n",
       "1   2  7574516   40          10         single          rented            no   \n",
       "2   3  3991815   66           4        married          rented            no   \n",
       "3   4  6256451   41           2         single          rented           yes   \n",
       "4   5  5768871   47          11         single          rented            no   \n",
       "\n",
       "            Profession                 CITY           STATE  CURRENT_JOB_YRS  \\\n",
       "0  Mechanical_engineer                 Rewa  Madhya_Pradesh                3   \n",
       "1   Software_Developer             Parbhani     Maharashtra                9   \n",
       "2     Technical_writer            Alappuzha          Kerala                4   \n",
       "3   Software_Developer          Bhubaneswar          Odisha                2   \n",
       "4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu                3   \n",
       "\n",
       "   CURRENT_HOUSE_YRS  Risk_Flag  \n",
       "0                 13          0  \n",
       "1                 13          0  \n",
       "2                 10          0  \n",
       "3                 12          1  \n",
       "4                 14          1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assuming the CSV file is located inside the downloaded directory\n",
    "path = os.path.join(path, 'Training Data.csv') #setting the path to the CSV file of the training data\n",
    "\n",
    "#read the CSV file using the file_path\n",
    "data = pd.read_csv(path) #reading the CSV file into a pandas DataFrame\n",
    "\n",
    "data.head() #print the first few rows of the DataFrame to see if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the title of the web app\n",
    "st.title(\"Interactive Unsupervised ML App: Predicting Loans Based on Customer Behavior\")\n",
    "\n",
    "#adding a description of the apps functionality \n",
    "st.write(\"This app uses unsupervised machine learning techniques to predict loan approvals based on customer behavior data.\") \n",
    "\n",
    "#asking the user to be interactive\n",
    "st.sidebar.header(\"1. Upload or Select Dataset\")\n",
    "\n",
    "sample_dataset = {\n",
    "    \"Prediction Dataset (only features)\": pd.read_csv(\"Sample Prediction Dataset.csv\"),\n",
    "    \"Test Dataset\": pd.read_csv(\"Test Data.csv\"),\n",
    "}\n",
    "dataset_option = st.sidebar.selectbox(\"Choose a dataset\", options=[\"Upload your own\"] + list(sample_dataset.keys()))\n",
    "\n",
    "#if else loop to check if the user has uploaded a file or selected a sample dataset and proceed accordingly\n",
    "if dataset_option == \"Upload your own\":\n",
    "    uploaded_file = st.sidebar.file_uploader(\"Upload CSV\", type=[\"csv\"])\n",
    "    if uploaded_file:\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "    else:\n",
    "        st.warning(\"Please upload a CSV to continue.\")\n",
    "        st.stop()\n",
    "else:\n",
    "    df = sample_dataset[dataset_option] #if the user is not uploading a file, they can select a sample dataset\n",
    "\n",
    "st.write(\"You selected:\", dataset_option , \". Here is a preview of your data.\") #displaying the name of the selected dataset\n",
    "st.dataframe(data.head()) #displaying the first few rows of the DataFrame to see if the upload worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this step, I will use PCA to reduce the dimensionality of the dataset and make it easier to use\n",
    "\n",
    "#preprocessing for PCA: dropping non numerical values\n",
    "X = df.select_dtypes(include=[np.number]).dropna()\n",
    "\n",
    "#ask users for input on choosing the number of PCA components and K-Means clusters\n",
    "st.sidebar.header(\"2. Set Model Parameters\")\n",
    "\n",
    "# PCA Components\n",
    "n_components = st.sidebar.slider(\"Number of PCA components\", 2, min(10, X.shape[1]), 2)\n",
    "#by having a slider the user is able to easily visualize the number of components they are selecting\n",
    "\n",
    "# K-Means Clusters\n",
    "n_clusters = st.sidebar.slider(\"Number of K-Means clusters\", 2, 10, 3)\n",
    "#the slider is effective in the same way for selecting the number of clusters\n",
    "\n",
    "#importing PCA\n",
    "# centering and scaling it because PCA is sensitive to the scale of the data\n",
    "    #Centering ensures that each feature has a mean of zero, and scaling ensures that each feature has unit variance.\n",
    "    #This prevents features with larger numerical ranges from dominating the PCA results.\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#actually scaling the data\n",
    "X_scaled = scaler.fit_transform(X) \n",
    "\n",
    "#reducing the data to 2 components for visualization and further analysis.\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "#displaying the Explained Variance Ratio. This tells us the proportion of the variance that is explained by each of the selected components.\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(\"Explained Variance Ratio:\", explained_variance)\n",
    "print(\"Cumulative Explained Variance:\", np.cumsum(explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this next step I will run K means. I chose to do KMeans clustering instead of hierarchical clustering because KMeans is more scalable\n",
    "#importing KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#setting the number of clusters to 2, as we have two classes (malignant and benign) #FIX THIS\n",
    "k = 2\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "#outputting the centroids and first few cluster assignments\n",
    "print(\"Centroids:\\n\", kmeans.cluster_centers_)\n",
    "print(\"First 10 cluster labels:\", clusters[:10])\n",
    "\n",
    "#or\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add cluster labels to DataFrame for plotting\n",
    "df_clustered = pd.DataFrame(X_pca, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
    "df_clustered['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I am going to plot results \n",
    "\n",
    "if n_components >= 2:\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(x=\"PC1\", y=\"PC2\", hue=\"Cluster\", data=df_clustered, palette=\"tab10\", ax=ax)\n",
    "    ax.set_title(\"K-Means Clusters (PCA-reduced)\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "#this evaluates thr right number of clusters\n",
    "st.sidebar.header(\"3. Optional: Elbow Plot\")\n",
    "if st.sidebar.button(\"Generate Elbow Plot\"):\n",
    "    distortions = []\n",
    "    K_range = range(1, 11)\n",
    "    for k in K_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42)\n",
    "        km.fit(X_pca)\n",
    "        distortions.append(km.inertia_)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.plot(K_range, distortions, marker='o')\n",
    "    ax2.set_title(\"Elbow Method for Optimal Clusters\")\n",
    "    ax2.set_xlabel(\"Number of clusters\")\n",
    "    ax2.set_ylabel(\"Inertia\")\n",
    "    st.pyplot(fig2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
